{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1gnn9ANgWg/SJgJ32Iw2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aristriana/KI_Tasks/blob/main/TaskWeek7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Aristriana Muhamad<br>\n",
        "NPM: 2106709043"
      ],
      "metadata": {
        "id": "tmvcoljM4xW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis"
      ],
      "metadata": {
        "id": "DQ82xfq347iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "!pip install transformers torch evaluate --quiet\n"
      ],
      "metadata": {
        "id": "oY0M9ZAx0gwV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries from transformers and evaluate\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import evaluate\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = 'finiteautomata/bertweet-base-sentiment-analysis'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Define the sentiment analysis function to show POS, NEU, NEG scores\n",
        "def analyze_sentiment(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Get the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the logits and apply softmax to get probabilities\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1).flatten().tolist()\n",
        "\n",
        "    # Map the probabilities to each sentiment\n",
        "    sentiment_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "    sentiment_scores = {\n",
        "        \"NEG\": probabilities[0],\n",
        "        \"NEU\": probabilities[1],\n",
        "        \"POS\": probabilities[2]\n",
        "    }\n",
        "\n",
        "    # Get the predicted sentiment\n",
        "    sentiment_label = torch.argmax(logits, dim=1).item()\n",
        "    predicted_sentiment = sentiment_mapping[sentiment_label]\n",
        "\n",
        "    return predicted_sentiment, sentiment_scores\n",
        "\n",
        "# Test the function with a sample text\n",
        "sample_text = \"I love using this model for sentiment analysis!\"\n",
        "predicted_sentiment, sentiment_scores = analyze_sentiment(sample_text)\n",
        "print(f\"Sentiment: {predicted_sentiment}\")\n",
        "print(f\"Scores: {sentiment_scores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dHNiYk70iAB",
        "outputId": "0da003a3-07b3-4add-9c53-d2595cd2d3cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Positive\n",
            "Scores: {'NEG': 0.0016961999936029315, 'NEU': 0.006148709449917078, 'POS': 0.992155134677887}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy using the evaluate library\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def calculate_accuracy(texts, labels):\n",
        "    predictions = []\n",
        "\n",
        "    for text, actual_label in zip(texts, labels):\n",
        "        predicted_sentiment, _ = analyze_sentiment(text)\n",
        "        # Convert sentiment string to label (0 for NEG, 1 for NEU, 2 for POS)\n",
        "        label_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
        "        predicted_label = label_mapping[predicted_sentiment]\n",
        "        predictions.append(predicted_label)\n",
        "\n",
        "        # Print the predicted and actual labels\n",
        "        actual_sentiment = list(label_mapping.keys())[list(label_mapping.values()).index(actual_label)]\n",
        "        #print(f\"Text: {text}\")\n",
        "        #print(f\"Predicted: {predicted_sentiment} (Label: {predicted_label}), Actual: {actual_sentiment} (Label: {actual_label})\\n\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    results = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    return results[\"accuracy\"]\n",
        "\n",
        "# Test accuracy calculation\n",
        "test_texts = [\n",
        "    \"I am extremely happy with the results!\",\n",
        "    \"The service was okay, nothing special.\",\n",
        "    \"I am very disappointed with the quality.\"\n",
        "]\n",
        "\n",
        "test_labels = [2, 1, 0]  # POS, NEU, NEG\n",
        "accuracy = calculate_accuracy(test_texts, test_labels)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pPVaJfp0xzg",
        "outputId": "51212c23-2271-4c34-951c-520dc2ef7962"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check the model’s accuracy using a synthetic dataset"
      ],
      "metadata": {
        "id": "3XJCGQPAcT7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a synthetic dataset with 300 examples (100 for each sentiment class)\n",
        "import random\n",
        "\n",
        "# Sample synthetic texts for each sentiment\n",
        "positive_texts = [\n",
        "    \"I absolutely love this product!\",\n",
        "    \"This is the best experience I’ve ever had.\",\n",
        "    \"Amazing service, I’m very satisfied!\",\n",
        "    \"The quality exceeded my expectations.\",\n",
        "    \"I'm thrilled with the results!\",\n",
        "    \"This is fantastic and I’m very happy.\",\n",
        "    \"I couldn’t be more pleased with how this turned out.\",\n",
        "    \"Outstanding job, well done!\",\n",
        "    \"This is perfect, just what I needed.\",\n",
        "    \"I’m super happy with this decision.\"\n",
        "] * 10  # Repeat to get 100 samples\n",
        "\n",
        "neutral_texts = [\n",
        "    \"The product is fine, nothing special.\",\n",
        "    \"This is okay, just as expected.\",\n",
        "    \"It's an average experience overall.\",\n",
        "    \"The quality is neither good nor bad.\",\n",
        "    \"It’s a standard service, nothing to complain about.\",\n",
        "    \"I'm indifferent about the results.\",\n",
        "    \"This is adequate but not outstanding.\",\n",
        "    \"I guess it's alright, not too impressive.\",\n",
        "    \"The experience was neither here nor there.\",\n",
        "    \"It's pretty much what I expected.\"\n",
        "] * 10  # Repeat to get 100 samples\n",
        "\n",
        "negative_texts = [\n",
        "    \"I’m very disappointed with this product.\",\n",
        "    \"The service was terrible and unsatisfactory.\",\n",
        "    \"This is the worst experience I’ve ever had.\",\n",
        "    \"The quality is far below my expectations.\",\n",
        "    \"I'm unhappy with how things turned out.\",\n",
        "    \"This is not good, I'm really frustrated.\",\n",
        "    \"A very poor experience overall.\",\n",
        "    \"This didn’t meet my expectations at all.\",\n",
        "    \"I'm upset and will not recommend this.\",\n",
        "    \"It was a waste of time and money.\"\n",
        "] * 10  # Repeat to get 100 samples\n",
        "\n",
        "# Combine the datasets\n",
        "synthetic_texts = positive_texts + neutral_texts + negative_texts\n",
        "synthetic_labels = [2] * 100 + [1] * 100 + [0] * 100  # 2 for POS, 1 for NEU, 0 for NEG\n",
        "\n",
        "# Shuffle the dataset to mix the samples\n",
        "combined = list(zip(synthetic_texts, synthetic_labels))\n",
        "random.shuffle(combined)\n",
        "synthetic_texts, synthetic_labels = zip(*combined)\n",
        "\n",
        "# Calculate accuracy on the synthetic dataset\n",
        "accuracy = calculate_accuracy(synthetic_texts, synthetic_labels)\n",
        "print(f\"Accuracy on synthetic dataset: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHkYNQTB39tS",
        "outputId": "d8c94f7b-a2a6-4fe4-c7c0-75c748c86ad7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on synthetic dataset: 76.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implement attention transformer and compare with the original model"
      ],
      "metadata": {
        "id": "MC2yUHHqcGdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the dataset using PyTorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForSequenceClassification, AdamW\n",
        "\n",
        "# Define a custom dataset class for PyTorch\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # Return the encoded inputs and the label\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create the training and evaluation datasets\n",
        "train_texts, eval_texts, train_labels, eval_labels = train_test_split(\n",
        "    synthetic_texts, synthetic_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "eval_dataset = SentimentDataset(eval_texts, eval_labels, tokenizer)\n",
        "\n",
        "# Define the model, optimizer, and loss function\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model using a PyTorch training loop\n",
        "def train_model(model, train_dataset, eval_dataset, epochs=3, batch_size=8):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in eval_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "                # Calculate accuracy\n",
        "                correct_predictions += torch.sum(preds == labels)\n",
        "                total_predictions += labels.size(0)\n",
        "\n",
        "        accuracy = correct_predictions.double() / total_predictions\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Evaluation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_dataset, eval_dataset)\n",
        "\n",
        "# Evaluate the fine-tuned model's accuracy on the entire synthetic dataset\n",
        "def evaluate_model_pytorch(model, texts, labels):\n",
        "    dataset = SentimentDataset(texts, labels, tokenizer)\n",
        "    data_loader = DataLoader(dataset, batch_size=8)\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "    accuracy = correct_predictions.double() / total_predictions\n",
        "    return accuracy.item()\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "fine_tuned_accuracy = evaluate_model_pytorch(model, synthetic_texts, synthetic_labels)\n",
        "print(f\"Fine-tuned Model Accuracy on synthetic dataset: {fine_tuned_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compare with original model accuracy\n",
        "original_model_accuracy = calculate_accuracy(synthetic_texts, synthetic_labels)\n",
        "print(\"\\nComparison of Accuracies:\")\n",
        "print(f\"Original Model Accuracy: {original_model_accuracy * 100:.2f}%\")\n",
        "print(f\"Fine-tuned Transformer Model Accuracy: {fine_tuned_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmq4v6Oz6hka",
        "outputId": "8cd09a56-70ab-4167-ea4f-29e461ab5a7a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Training Loss: 0.0735\n",
            "Epoch 1/3, Evaluation Accuracy: 1.0000\n",
            "Epoch 2/3, Training Loss: 0.0121\n",
            "Epoch 2/3, Evaluation Accuracy: 1.0000\n",
            "Epoch 3/3, Training Loss: 0.0077\n",
            "Epoch 3/3, Evaluation Accuracy: 1.0000\n",
            "Fine-tuned Model Accuracy on synthetic dataset: 100.00%\n",
            "\n",
            "Comparison of Accuracies:\n",
            "Original Model Accuracy: 100.00%\n",
            "Fine-tuned Transformer Model Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}